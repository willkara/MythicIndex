name: Migrate Images to Cloudflare

on:
  workflow_dispatch:
    inputs:
      dry_run:
        description: "Run in dry-run mode (preview only)"
        required: false
        default: "true"
        type: choice
        options:
          - "true"
          - "false"
      batch_size:
        description: "Number of images to process in one run"
        required: false
        default: "100"

env:
  PYTHON_VERSION: "3.11"

jobs:
  migrate-images:
    name: Migrate Images to Cloudflare
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          lfs: true # If using Git LFS for images

      - name: Checkout LFS objects
        run: git lfs pull || echo "No LFS objects found"

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Install dependencies
        run: |
          pip install httpx rich sqlalchemy aiosqlite asyncpg psycopg2-binary pillow

      - name: Create migration script
        run: |
          cat > migrate_images.py << 'SCRIPT_EOF'
          #!/usr/bin/env python3
          """Migrate MemoryQuill images to Cloudflare Images"""

          import asyncio
          import os
          import sys
          from pathlib import Path
          from typing import List, Dict
          import httpx
          from rich.console import Console
          from rich.progress import track

          console = Console()

          CF_ACCOUNT_ID = os.getenv("CF_ACCOUNT_ID")
          CF_API_TOKEN = os.getenv("CF_API_TOKEN")
          CF_IMAGES_API = f"https://api.cloudflare.com/client/v4/accounts/{CF_ACCOUNT_ID}/images/v1"
          DRY_RUN = os.getenv("DRY_RUN", "true").lower() == "true"
          BATCH_SIZE = int(os.getenv("BATCH_SIZE", "100"))

          async def upload_to_cloudflare(image_path: Path, image_id: str) -> Dict:
              """Upload image to Cloudflare Images"""

              if DRY_RUN:
                  console.print(f"[yellow]DRY RUN:[/yellow] Would upload {image_path} as {image_id}")
                  return {"success": True, "dry_run": True, "id": image_id}

              headers = {"Authorization": f"Bearer {CF_API_TOKEN}"}

              try:
                  with open(image_path, "rb") as f:
                      files = {"file": f}
                      data = {"id": image_id}

                      async with httpx.AsyncClient(timeout=60.0) as client:
                          response = await client.post(
                              CF_IMAGES_API,
                              headers=headers,
                              files=files,
                              data=data
                          )

                          if response.status_code == 200:
                              result = response.json()
                              console.print(f"[green]âœ“[/green] Uploaded {image_id}")
                              return {"success": True, **result}
                          else:
                              console.print(f"[red]âœ—[/red] Failed {image_id}: {response.text}")
                              return {"success": False, "error": response.text}
              except Exception as e:
                  console.print(f"[red]Error uploading {image_id}:[/red] {e}")
                  return {"success": False, "error": str(e)}

          async def migrate_images():
              """Main migration function"""

              images_dir = Path("gpt-images")
              if not images_dir.exists():
                  console.print(f"[red]Error:[/red] Images directory not found: {images_dir}")
                  return

              # Find all images
              all_images = []
              for pattern in ["**/*.jpg", "**/*.jpeg", "**/*.png", "**/*.webp"]:
                  all_images.extend(list(images_dir.glob(pattern)))

              # Limit to batch size
              all_images = all_images[:BATCH_SIZE]

              console.print(f"\n[bold]Found {len(all_images)} images to migrate[/bold]")
              if DRY_RUN:
                  console.print("[yellow]Running in DRY RUN mode[/yellow]\n")

              results = {"success": [], "failed": [], "skipped": []}

              for image_path in track(all_images, description="Processing images..."):
                  # Generate image ID from path
                  image_id = image_path.stem

                  # Check if already exists (in production mode)
                  if not DRY_RUN:
                      headers = {"Authorization": f"Bearer {CF_API_TOKEN}"}
                      async with httpx.AsyncClient() as client:
                          check_url = f"{CF_IMAGES_API}/{image_id}"
                          check_response = await client.get(check_url, headers=headers)
                          if check_response.status_code == 200:
                              console.print(f"[yellow]âŠ˜[/yellow] Skipped {image_id} (already exists)")
                              results["skipped"].append(image_id)
                              continue

                  result = await upload_to_cloudflare(image_path, image_id)

                  if result.get("success"):
                      results["success"].append(image_id)
                  else:
                      results["failed"].append(image_id)

              # Print summary
              console.print(f"\n[bold]Migration Summary[/bold]")
              console.print(f"  [green]Success:[/green] {len(results['success'])}")
              console.print(f"  [red]Failed:[/red] {len(results['failed'])}")
              console.print(f"  [yellow]Skipped:[/yellow] {len(results['skipped'])}")

              # Write results to file for GitHub Actions
              with open("migration_results.txt", "w") as f:
                  f.write(f"SUCCESS={len(results['success'])}\n")
                  f.write(f"FAILED={len(results['failed'])}\n")
                  f.write(f"SKIPPED={len(results['skipped'])}\n")

              return results

          if __name__ == "__main__":
              if not CF_ACCOUNT_ID or not CF_API_TOKEN:
                  console.print("[red]Error:[/red] CF_ACCOUNT_ID and CF_API_TOKEN must be set")
                  sys.exit(1)

              asyncio.run(migrate_images())
          SCRIPT_EOF

          chmod +x migrate_images.py

      - name: Run image migration
        env:
          CF_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CF_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          DRY_RUN: ${{ inputs.dry_run }}
          BATCH_SIZE: ${{ inputs.batch_size }}
        run: |
          python migrate_images.py

      - name: Read migration results
        id: results
        run: |
          if [ -f migration_results.txt ]; then
            cat migration_results.txt
            cat migration_results.txt >> $GITHUB_OUTPUT
          else
            echo "SUCCESS=0" >> $GITHUB_OUTPUT
            echo "FAILED=0" >> $GITHUB_OUTPUT
            echo "SKIPPED=0" >> $GITHUB_OUTPUT
          fi

      - name: Add migration summary
        run: |
          echo "### ðŸ–¼ï¸ Image Migration Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Mode:** ${{ inputs.dry_run == 'true' && 'Dry Run' || 'Production' }}" >> $GITHUB_STEP_SUMMARY
          echo "**Batch Size:** ${{ inputs.batch_size }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Status | Count |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| âœ… Success | ${{ steps.results.outputs.SUCCESS }} |" >> $GITHUB_STEP_SUMMARY
          echo "| âŒ Failed | ${{ steps.results.outputs.FAILED }} |" >> $GITHUB_STEP_SUMMARY
          echo "| âŠ˜ Skipped | ${{ steps.results.outputs.SKIPPED }} |" >> $GITHUB_STEP_SUMMARY

      - name: Upload migration logs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: migration-logs
          path: |
            migration_results.txt
          retention-days: 30

  sync-to-r2:
    name: Sync Static Assets to R2
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS CLI for R2
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.R2_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          aws-region: auto

      - name: Sync frontend assets to R2
        run: |
          aws s3 sync ./frontend/src/assets s3://memoryquill-assets/assets \
            --endpoint-url https://${{ secrets.CLOUDFLARE_ACCOUNT_ID }}.r2.cloudflarestorage.com \
            --exclude "*.map" \
            --cache-control "public, max-age=31536000" \
            --only-show-errors

      - name: Sync chapter banners to R2 (if exists)
        run: |
          if [ -d "./gpt-images/chapters" ]; then
            aws s3 sync ./gpt-images/chapters s3://memoryquill-assets/chapters \
              --endpoint-url https://${{ secrets.CLOUDFLARE_ACCOUNT_ID }}.r2.cloudflarestorage.com \
              --cache-control "public, max-age=31536000" \
              --only-show-errors
          else
            echo "No chapter banners directory found, skipping..."
          fi

      - name: List R2 contents
        run: |
          echo "### ðŸ“¦ R2 Bucket Contents" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          aws s3 ls s3://memoryquill-assets/ \
            --endpoint-url https://${{ secrets.CLOUDFLARE_ACCOUNT_ID }}.r2.cloudflarestorage.com \
            --recursive --human-readable --summarize >> $GITHUB_STEP_SUMMARY || echo "Failed to list" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
